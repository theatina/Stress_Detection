{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"___\n___\n# M908 NLP - miniProject: **Stress Detection**\n___\n___\n### Kylafi Christina-Theano (Theatina)\nLT1200012\n___","metadata":{}},{"cell_type":"markdown","source":"___\n___\n# Feature Engineering Experiments\n___","metadata":{}},{"cell_type":"markdown","source":"## Emotion Detection","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n#---------- emotion dictionary ---------------------------------------------------------------------------------------------------------------------------------\ndef add_emotion_dictionary(df):\n    classifier = pipeline(\"text-classification\", model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True)\n    \n    emotions_preds = [ { pred['label']:pred['score'] for pred in classifier( t )[0] } for t in df['text'] ]\n    df['emotion_dict'] = emotions_preds\n\n    return df\n\ndef add_emotionNscore(df):\n    emotion_dom = []\n    emotion_score = []\n    progress_bar = tqdm.tqdm(range(df.shape[0]))\n    for i,row in df.iterrows():\n        em_dict = row['emotion_dict']\n        emotion_dom.append(max(em_dict, key=em_dict.get))\n        emotion_score.append(max(em_dict.values()))\n        progress_bar.update(1)\n    \n    df['emotion'] = emotion_dom\n    df['emotion_score'] = emotion_score\n    return df\n\n\n# add_emotion_dictionary(train_df)\n# add_emotion_dictionary(test_df)\n\n# add_emotionNscore(train_df)\n# add_emotionNscore(test_df)\n\n# train_df.to_csv(os.path.join(file_store_dir,\"stressTrain.csv\"),  index = False, header=True)\n# test_df.to_csv(os.path.join(file_store_dir,\"stressTest.csv\"),  index = False, header=True)\n\n\n#---------- depression dictionary ------------------------------------------------------------------------------------------------------------------------\ndef add_depression_dictionary(df):\n    classifier = pipeline(\"text-classification\", model=\"paulagarciaserrano/roberta-depression-detection\", return_all_scores=True)\n\n    depression_preds = [ { pred['label']:pred['score'] for pred in classifier( t )[0] } for t in df['text'] ]\n    df['depression_dict'] = depression_preds\n\n\n\ndef add_depressionNscore(df):\n    depression_dom = []\n    depression_score = []\n    progress_bar = tqdm.tqdm(range(df.shape[0]))\n    for i,row in df.iterrows():\n        depr_dict = row['depression_dict']\n        depression_dom.append(max(depr_dict, key=depr_dict.get))\n        depression_score.append(max(depr_dict.values()))\n        progress_bar.update(1)\n    \n    df['depression'] = depression_dom\n    df['depression_score'] = depression_score\n\n\n# add_depression_dictionary(train_df)\n# add_depressionNscore(train_df)\n\n# add_depression_dictionary(test_df)\n# add_depressionNscore(test_df)\n\n# train_df.to_csv(os.path.join(file_store_dir,\"stressTrainEmDepr.csv\"),  index = False, header=True)\n# test_df.to_csv(os.path.join(file_store_dir,\"stressTestEmDepr.csv\"),  index = False, header=True)\n\n\n#---------- data visualization ------------------------------------------------------------------------------------------------------------------------\ndef data_vis(file_store_dir, train_df, test_df):\n    plot_dir = os.path.join(file_store_dir,\"figures\")\n    if not os.path.exists(plot_dir):\n        os.makedirs(plot_dir)\n\n    # plt.clf()\n    df=train_df.groupby(['subreddit']).size()\n    # df=df.unstack()\n    df.plot(kind='bar', figsize=(15,8))\n    plt.xticks(rotation=45)\n    plt.savefig(os.path.join(plot_dir,\"subreddits.png\"), dpi=300)\n\n    # plt.clf()\n    df=train_df.groupby(['subreddit',\"label\"]).size()\n    df=df.unstack()\n    df.plot(kind='bar', figsize=(15,8))\n    plt.legend([\"No stress\", \"Stress\"])\n    plt.xticks(rotation=45)\n    plt.savefig(os.path.join(plot_dir,\"subredditsLabel.png\"), dpi=300)\n\n    # plt.clf()\n    df=train_df.groupby(['emotion',\"label\"]).size()\n    df=df.unstack()\n    df.plot(kind='bar', figsize=(15,8))\n    plt.legend([\"No stress\", \"Stress\"])\n    plt.xticks(rotation=0)\n    plt.savefig(os.path.join(plot_dir,\"emotionLabel.png\"), dpi=300)\n\n\n    df=train_df.groupby(['subreddit',\"emotion\"]).size()\n    df=df.unstack()\n    df.plot(kind='bar', figsize=(15,8))\n    # plt.legend([\"joy\", \"love\", \"anger\", \"sadness\", \"fear\", \"surprise\" ])\n    plt.xticks(rotation=45)\n    plt.savefig(os.path.join(plot_dir,\"subredditEmotion.png\"), dpi=300)\n\n\n    df=train_df.groupby(['label',\"emotion\"]).size()\n    df=df.unstack()\n    df.plot(kind='bar', figsize=(15,8))\n    # plt.legend([\"joy\", \"love\", \"anger\", \"sadness\", \"fear\", \"surprise\" ])\n    plt.xticks([0,1],[\"no stress\", \"stress\"], rotation=0)\n    plt.savefig(os.path.join(plot_dir,\"labelEmotion.png\"), dpi=300)\n\n\n    df=train_df.groupby(['depression',\"emotion\"]).size()\n    df=df.unstack()\n    df.plot(kind='bar', figsize=(15,8))\n    # plt.legend([\"joy\", \"love\", \"anger\", \"sadness\", \"fear\", \"surprise\" ])\n    plt.xticks([0,1,2],[\"moderate\", \"not depression\", \"severe\"], rotation=0)\n    plt.savefig(os.path.join(plot_dir,\"depressionEmotion\"), dpi=300)\n\n\n    plt.clf()\n    df1 = train_df[train_df['label'] == 0]\n    df2 = train_df[train_df['label'] == 1]\n\n    ax = df1.plot(x='emotion', y='emotion_score', kind='scatter', c='g', label='Not stressed', figsize=(15,12))\n    df2.plot(x='emotion', y='emotion_score', kind='scatter', ax=ax, c='r', label='Stressed')\n    ax.hlines(.5, -0.2,5.2, linestyles='dashed')\n    ax.annotate('threshold',(-0.4,0.51))\n    plt.show()\n\n\n    df1 = train_df[train_df['emotion'] == \"joy\"]\n    df2 = train_df[train_df['emotion'] == \"love\"]\n    df3 = train_df[train_df['emotion'] == \"anger\"]\n    df4 = train_df[train_df['emotion'] == \"sadness\"]\n    df5 = train_df[train_df['emotion'] == \"fear\"]\n    df6 = train_df[train_df['emotion'] == \"surprise\"]\n\n\n    x_col = 'lex_liwc_negemo'\n    y_col = 'lex_liwc_posemo'\n\n    ax = df1.plot(x=x_col, y=y_col, kind='scatter', c='g', label='joy', figsize=(15,12))\n    df2.plot(x=x_col, y=y_col, kind='scatter', ax=ax, c='m', label='love')\n    df3.plot(x=x_col, y=y_col, kind='scatter', ax=ax, c='r', label='anger')\n    df4.plot(x=x_col, y=y_col, kind='scatter', ax=ax, c='b', label='sadness')\n    df5.plot(x=x_col, y=y_col, kind='scatter', ax=ax, c='c', label='fear')\n    df6.plot(x=x_col, y=y_col, kind='scatter', ax=ax, c='y', label='surprise')\n\n    plt.show()\n\n\n    # plt.savefig(os.path.join(plot_dir,\"emotionEmScore.png\"), dpi=300)\n\n\n    # df=train_df.groupby(['subreddit']).size()\n    # # df=df.unstack()\n    # df.plot(kind='bar', figsize=(15,8))\n    # plt.savefig(os.path.join(file_store_dir,\"subreddits.png\"), dpi=300)\n\n    t_df = train_df\n\n    df=t_df[t_df[\"label\"]==0].groupby(['subreddit',\"emotion\"]).size()\n    df=df.unstack()\n    df.plot(kind='bar', figsize=(15,8))\n    # plt.legend([\"joy\", \"love\", \"anger\", \"sadness\", \"fear\", \"surprise\" ])\n    plt.xticks(rotation=45)\n    plt.savefig(os.path.join(\"./subredditEmotion_label_0.png\"), dpi=300)\n    plt.title(\"Not stressed\")\n#     plt.show()\n\n\n    df=t_df[t_df[\"label\"]==1].groupby(['subreddit',\"emotion\"]).size()\n    df=df.unstack()\n    df.plot(kind='bar', figsize=(15,8))\n    # plt.legend([\"joy\", \"love\", \"anger\", \"sadness\", \"fear\", \"surprise\" ])\n    plt.xticks(rotation=45)\n    plt.savefig(os.path.join(\"./subredditEmotion_label_1.png\"), dpi=300)\n    plt.title(\"Stressed\")\n#     plt.show()\n\n\n\n# columns_to_file(train_df,file_store_dir)\n# !cat ./results/columns.txt","metadata":{"execution":{"iopub.status.busy":"2022-07-05T17:28:08.521155Z","iopub.execute_input":"2022-07-05T17:28:08.521775Z","iopub.status.idle":"2022-07-05T17:28:08.55471Z","shell.execute_reply.started":"2022-07-05T17:28:08.521738Z","shell.execute_reply":"2022-07-05T17:28:08.553919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train_embs = \"/kaggle/working/stressTrainEmDep_BERTnWord2Vec_text.csv\"\ndataset_test_embs = \"/kaggle/working/stressTestEmDep_BERTnWord2Vec_text.csv\"\n\nif not os.path.exists(dataset_train_embs):\n    !gdown 19ZMTk5ZwmyL_eVVhXGC_kAdFTReu25Nm \n    !gdown 1XcaYJ78vXov-yhyBFDUWx2rH7DbeKx5k\n\ntrain_df = pd.read_csv(dataset_train_embs)\ntest_df = pd.read_csv(dataset_test_embs)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:28:08.713151Z","iopub.execute_input":"2022-07-13T19:28:08.713784Z","iopub.status.idle":"2022-07-13T19:28:19.826127Z","shell.execute_reply.started":"2022-07-13T19:28:08.713744Z","shell.execute_reply":"2022-07-13T19:28:19.825107Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"___\n___\n# **Stress Detection Task** \n___\n___","metadata":{}},{"cell_type":"code","source":"#---------- RESULTS FILE DIRECTORY ---------------------------------------------------------------------- \n\nfile_store_dir=\"/kaggle/working/results\"","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:21:10.078472Z","iopub.execute_input":"2022-07-13T19:21:10.079597Z","iopub.status.idle":"2022-07-13T19:21:10.110375Z","shell.execute_reply.started":"2022-07-13T19:21:10.079480Z","shell.execute_reply":"2022-07-13T19:21:10.109119Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -U huggingface_hub\n!pip install gensim\n!pip install nltk\n!pip install gdown\n\n# modules\nimport pandas as pd\nimport os\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.corpus import stopwords\nimport tqdm\nimport numpy as np\nfrom numpy import mean\nfrom numpy import std\nfrom datasets import load_metric\nimport random\nfrom IPython.display import FileLink, FileLinks\n\nimport torch\nfrom torch.utils.data import DataLoader, RandomSampler, TensorDataset\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom transformers import pipeline\n\nimport transformers\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer, AutoModel, BertTokenizer, BertModel\n\nfrom keras import backend as K\nfrom keras import Model\nfrom keras.models import Sequential\nfrom keras.layers import Input, Embedding, LSTM, Dense, Dropout, concatenate, Bidirectional, Conv1D, Conv2D, Flatten, MaxPooling1D, MaxPooling2D, GlobalMaxPool1D, GRU, CuDNNGRU\nfrom keras.preprocessing import sequence\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nfrom keras.callbacks import CSVLogger\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, KFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n\nimport warnings\nwarnings.filterwarnings(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\npiplist = !pip freeze\nif not ( \"GPUtil\" in \" \".join([ p for p in piplist ]) ):\n    !pip install GPUtil\n    print(\"\\n\\n\")\nfrom GPUtil import showUtilization as gpu_usage\nimport gc\nfrom numba import cuda\n\n\n# output dir\nif not os.path.exists(file_store_dir):\n    os.makedirs(file_store_dir)\n\n\n\n#Importing librariesfrom nltk.tokenize import sent_tokenize, word_tokenize\nimport gensim\nfrom gensim.models import Word2Vec, KeyedVectors","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:21:10.115661Z","iopub.execute_input":"2022-07-13T19:21:10.116015Z","iopub.status.idle":"2022-07-13T19:22:49.625226Z","shell.execute_reply.started":"2022-07-13T19:21:10.115986Z","shell.execute_reply":"2022-07-13T19:22:49.623957Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"___\n___\n## Functions \n___","metadata":{}},{"cell_type":"code","source":"#---------- DATA PRE PROCESSING ------------------------------------------------------------------------------\n\ndef stamp_to_date(timestamp):\n    return datetime.fromtimestamp(timestamp)\n\ndef load_data(dataset_path):\n    return pd.read_csv(dataset_path)\n\ndef columns_to_dict(df):\n    columns_dict = {}\n    for i,c in enumerate(df.columns):\n        columns_dict[c] = list(set(df[c]))\n    return columns_dict\n\ndef add_tokens_col(df):\n    text_token_list = []\n    for i,row in df.iterrows():\n        tok = TweetTokenizer()\n        tokens = tok.tokenize(row['text'])\n        tokens = [ t for t in tokens if t.isalnum() and t not in stopwords.words('english') ]\n        text_token_list.append(tokens)\n    \n    df[\"tokens\"] = text_token_list\n    return df\n\ndef df_to_csv(df, filedir, filename):\n    if \".csv\" not in filename:\n        filename+=\".csv\"\n    df.to_csv(os.path.join(filedir,filename), sep='\\t', encoding='utf-8')\n\ndef text_tokenizer(tokenizer, texts):\n    tok_texts = []\n    for text in tqdm.tqdm(texts, desc = 'Tokenizing texts'):\n        tokens = tokenizer.tokenize(text)\n        ids = tokenizer.convert_tokens_to_ids(tokens)\n        tok_texts.append(ids)\n    return tok_texts\n\ndef alpha_to_numerical(alpha_feats_df):\n    le = LabelEncoder()\n    return le.fit_transform(alpha_feats_df), le\n\ndef columns_to_file(df, file_store_dir, filename):\n    columns_file = os.path.join(file_store_dir,f\"{filename}.txt\")\n    columns_dict = {}\n    with open(columns_file, \"w+\", encoding=\"utf-8\") as writer:\n        for i,c in enumerate(df.columns):\n            if c in [\"emotion_dict\", \"depression_dict\"]:\n                columns_dict[c] = list(eval(df[c][0]).keys())\n            else:\n                columns_dict[c] = df[c]\n            writer.write(f\"{i}. {c}\\n\")\n\n        writer.write(20*\"_\")\n        writer.write(f\"\\n\\n subreddits: {list(set(columns_dict['subreddit']))}\\n\")\n        writer.write(f\"\\n emotions: {columns_dict['emotion_dict']}\\n\")\n        writer.write(f\"\\n depression states: {columns_dict['depression_dict']}\\n\")\n        writer.write(f\"\\n social_timestamp range: [ {stamp_to_date(min(columns_dict['social_timestamp']))}, {stamp_to_date(max(columns_dict['social_timestamp']))} ]\\n\\n\")\n\n\ndef datasets_sortNclean(train_df,test_df):\n    # dataset rearrangement\n    train_df.insert(9, 'social_upvote_ratio', train_df.pop('social_upvote_ratio'))\n    train_df.insert(10, 'social_num_comments', train_df.pop('social_num_comments'))\n    train_df.insert(12, 'syntax_fk_grade', train_df.pop('syntax_fk_grade'))\n    train_df.pop(\"post_id\")\n    train_df.pop(\"id\")\n    train_df.pop(\"sentence_range\")\n    train_df.pop(\"confidence\")\n\n    test_df.insert(9, 'social_upvote_ratio', test_df.pop('social_upvote_ratio'))\n    test_df.insert(10, 'social_num_comments', test_df.pop('social_num_comments'))\n    test_df.insert(12, 'syntax_fk_grade', test_df.pop('syntax_fk_grade'))\n    test_df.pop(\"post_id\")\n    test_df.pop(\"id\")\n    test_df.pop(\"sentence_range\")\n    test_df.pop(\"confidence\")\n\n    for i,c in enumerate(test_df.columns):\n        print (i+1,c)\n\n\ndef columNames_to_file(df, file_store_dir, data_type):\n    columns_file = os.path.join(file_store_dir,f\"{data_type}_columns.txt\")\n    columns_dict = {}\n    with open(columns_file, \"w+\", encoding=\"utf-8\") as writer:\n        for i,c in enumerate(df.columns):\n            columns_dict[c] = df[c]\n            writer.write(f\"{i}. {c}\\n\")\n\n\ndef df_to_csv_PlusColumnNames(trainX_df, trainY_df, testX_df, testY_df, file_store_dir, data_type):       \n    columNames_to_file(trainX_df,file_store_dir,data_type)\n\n    trainX_df.to_csv(os.path.join(file_store_dir,f\"stressTrainX_{data_type}.csv\"),  index = False, header=True)\n    trainY_df.to_csv(os.path.join(file_store_dir,f\"stressTrainY_{data_type}.csv\"),  index = False, header=True)\n\n    testX_df.to_csv(os.path.join(file_store_dir,f\"stressTestX_{data_type}.csv\"),  index = False, header=True)\n    testY_df.to_csv(os.path.join(file_store_dir,f\"stressTestY_{data_type}.csv\"),  index = False, header=True)\n\n\ndef evaluate_model_precision(model, X, y):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=4, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='precision', cv=cv, n_jobs=-1, error_score='raise')\n    return scores\n\ndef evaluate_model_recall(model, X, y):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=4, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='recall', cv=cv, n_jobs=-1, error_score='raise')\n    return scores\n\ndef evaluate_model_f1(model, X, y):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=4, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='f1', cv=cv, n_jobs=-1, error_score='raise')\n    return scores\n\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n\n\ndef categorical_encoding(labels):\n    cat_enc = LabelEncoder()\n    cat_enc.fit(labels)\n    encoded_labels = cat_enc.transform(labels)\n    # convert integers to one hot encoding\n    return np_utils.to_categorical(encoded_labels)\n\n\n\n#---------- BERT SENTENCE EMBEDDINGS ------------------------------------------------------------------------------\n# Extract sentence embeddings from BERT based on article: \"BERT Word Embeddings Tutorial\" \n# (https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial\n\nBERT_EMB_OUT = 768\n\ndef BERT_tok_paddedXY(train_df,test_df, bert_tok_name='bert-base-uncased', max_length=-9):\n    print(\"\\nBERT tokenizer running..\\n\")\n    bert_tokenizer = transformers.BertTokenizer.from_pretrained(bert_tok_name)\n\n    # trainX,trainY = df[['text', 'lex_liwc_Tone', 'lex_liwc_negemo', 'lex_liwc_Clout','lex_liwc_i', 'sentiment' ]], df['label']\n    trainX_tok = text_tokenizer(bert_tokenizer, train_df['text'])\n    testX_tok = text_tokenizer(bert_tokenizer, test_df['text'])\n\n    # max length for padding will be the maximum length of the texts for optimization\n    trainX_tok_padded = sequence.pad_sequences(trainX_tok, padding='post')\n    if max_length==-9:\n        max_length = len(trainX_tok_padded[0])\n    testX_tok_padded = sequence.pad_sequences(testX_tok, padding='post', maxlen=max_length )\n\n    return trainX_tok_padded, testX_tok_padded, max_length\n\ndef batch_encodings(encodings, batch_size):\n    enc_batches = []\n\n#     randomize samples\n    num = len(encodings[\"input_ids\"])\n    in_tokens, type_tokens, mask = zip(*random.sample(list(zip(encodings[\"input_ids\"], encodings[\"token_type_ids\"], encodings[\"attention_mask\"])), num))\n    in_tokens, type_tokens, mask = list(in_tokens), list(type_tokens), list(mask)\n\n    done = 0\n    running = True\n    steps = len(in_tokens)\n    progress_bar = tqdm.tqdm(range(steps), desc =\"Batching Encodings\")\n    while running:\n        # `to_take` is our actual batch size. It will be `batch_size` until \n        # we get to the last batch, which may be smaller. \n        selected = min(batch_size, len(in_tokens) - done)\n\n        # Select a contiguous batch of samples starting at `select`.\n        start = done\n        end = start+selected\n        tok,types,mask = in_tokens[start:end], type_tokens[start:end], mask[start:end]\n\n        done+=selected\n        # Each sample is a tuple--split them apart to create a separate list of \n        # sequences and a list of labels for this batch.\n        enc_batches.append([tok,types,mask])\n\n        progress_bar.update(selected)\n        if done==end==len(in_tokens):\n            running=False\n\n    return enc_batches\n\n\ndef gpu_clean():   \n    gc.collect()\n    torch.cuda.empty_cache()\n    gpu_usage()\n\n#     cuda.select_device(0)\n#     cuda.close()\n#     cuda.select_device(0)\n\ndef BERT_sentence_emb(train_df_text, test_df_text, bert_tok_name='bert-base-uncased'):\n    gpu_clean()\n    # Sentences we want sentence embeddings for\n    sentences_train = list(train_df_text.values)\n    sentences_test = list(test_df_text.values)\n\n    # Load model from HuggingFace Hub\n    lower_text = \"uncased\" in bert_tok_name\n    tokenizer = transformers.BertTokenizer.from_pretrained(bert_tok_name,  do_lower_case=lower_text)\n    model = transformers.BertModel.from_pretrained(bert_tok_name, output_hidden_states=True)\n\n    # Tokenize sentences\n    encoded_input_train = tokenizer(sentences_train, padding=True, truncation=True, return_tensors='pt')\n    encoded_input_test = tokenizer(sentences_test, padding=True, truncation=True, return_tensors='pt')\n\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    print(f\"\\nRunning on {device}..\\n\")\n    model = model.to(device)\n    model.eval()\n    # Compute token embeddings\n#     train_sampler = RandomSampler(encoded_input_train)\n#     train_dataloader = DataLoader(encoded_input_train, sampler=train_sampler, batch_size=500)\n    print(f\"\\nCreating Text Embeddings\\n\")\n    batch_size=150\n#     train_dataloader = batch_encodings(encoded_input_train, batch_size)\n    train_dataset = TensorDataset(encoded_input_train[\"input_ids\"], encoded_input_train[\"token_type_ids\"], encoded_input_train[\"attention_mask\"])\n    train_sampler = RandomSampler(train_dataset)\n    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n\n    train_sentence_embeddings = []\n    steps = len(train_dataloader)\n    progress_bar = tqdm.tqdm(range(steps), desc =\"Training Sentence Embeddings\")\n    with torch.no_grad():\n        for batch_data in train_dataloader:\n            input_ids, token_type_ids, attention_mask = tuple(t.to(device) for t in batch_data)\n            model_output_train = model(input_ids, attention_mask, token_type_ids)\n            hid_states = model_output_train[2]\n#             hidden layer 12/13 and average token embeddings\n            tok_vecs = hid_states[-2]\n            train_sentence_embeddings.extend(torch.mean(tok_vecs,dim=1))\n            progress_bar.update(1)\n#     clear gpu & ram\n    del encoded_input_train\n    del model_output_train\n    gpu_clean()\n#     gpu_clean()\n\n#     model = model.to(device)\n    test_dataset = TensorDataset(encoded_input_test[\"input_ids\"], encoded_input_test[\"token_type_ids\"], encoded_input_test[\"attention_mask\"])\n    test_sampler = RandomSampler(test_dataset)\n    test_dataloader = DataLoader(train_dataset, sampler=test_sampler, batch_size=batch_size)\n\n    test_sentence_embeddings = []\n    steps = len(test_dataloader)\n    progress_bar = tqdm.tqdm(range(steps), desc =\"Test Sentence Embeddings\")\n    with torch.no_grad():\n        for batch_data in test_dataloader:\n            input_ids, token_type_ids, attention_mask = tuple(t.to(device) for t in batch_data)\n            model_output_test = model(input_ids, attention_mask, token_type_ids)\n            hid_states = model_output_test[2]\n#             hidden layer 12/13 and average token embeddings\n            tok_vecs = hid_states[-2]\n            test_sentence_embeddings.extend(torch.mean(tok_vecs,dim=1))\n            progress_bar.update(1)\n\n#     clean gpu & ram\n    del encoded_input_test\n    del model_output_test\n    gpu_clean()\n\n    return train_sentence_embeddings, test_sentence_embeddings\n\n# test_embs_test, test_embs_train = BERT_sentence_emb(train_df[\"text\"],test_df[\"text\"], bert_tok_name='bert-base-uncased')\n\ndef get_sentence_embs(train_sent_embs, test_sent_embs):\n    # save sentence embeddings\n    train_s_embs = [ embs.tolist() for embs in train_sent_embs ]\n    test_s_embs = [ embs.tolist() for embs in test_sent_embs ]\n\n    text_embed_names = [ str(i) for i in range(len(train_s_embs[0])) ]\n    train_embs = pd.DataFrame(train_s_embs, columns=text_embed_names)\n    test_embs = pd.DataFrame(test_s_embs, columns=text_embed_names)\n\n    return train_embs, test_embs\n\n#     train_embs.to_csv(os.path.join(file_store_dir,\"stressTrain_embs.csv\"), index = False, header=True)\n#     test_embs.to_csv(os.path.join(file_store_dir,\"stressTest_embs.csv\"), index = False, header=True)\n\n\n#---------- Word2Vec SENTENCE EMBEDDINGS ------------------------------------------------------------------------------\n# Extract sentence embeddings from BERT based on article: \"BERT Word Embeddings Tutorial\" \n# (https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial\n\nWORD2VEC_EMB_OUT = 300\n\n\n\n\n#---------- FEATURE SELECTION -----------------------------------------------------------------------------------------\ndef join_embs_feats(embeddings,features):\n    return embeddings.join(features)\n\ndef df_allFeats_split(train_df, test_df):\n    trainX_allFeats = pd.DataFrame(train_df)\n    trainX_allFeats.pop(\"text\")\n    if \"BERT\" in trainX_allFeats.columns:\n        trainX_allFeats.pop(\"BERT\")\n    if \"Word2Vec\" in trainX_allFeats.columns:\n        trainX_allFeats.pop(\"Word2Vec\")\n#     trainX_allFeats.pop(\"tokens\")\n    trainX_allFeats.pop(\"id\")\n    trainX_allFeats.pop(\"emotion_dict\")\n    trainX_allFeats.pop(\"depression_dict\")\n    trainX_allFeats.pop(\"post_id\")\n    trainX_allFeats.pop(\"sentence_range\")\n    trainX_allFeats.pop(\"social_timestamp\")\n    subreddit_encoded, sub_encoder = alpha_to_numerical(trainX_allFeats[\"subreddit\"])\n    trainX_allFeats[\"subreddit\"] = subreddit_encoded\n    emotion_encoded, em_encoder = alpha_to_numerical(trainX_allFeats[\"emotion\"])\n    trainX_allFeats[\"emotion\"] = emotion_encoded\n    depression_encoded, dep_encoder = alpha_to_numerical(trainX_allFeats[\"depression\"])\n    trainX_allFeats[\"depression\"] = depression_encoded\n    trainY_allFeats = trainX_allFeats[\"label\"]\n    trainX_allFeats.pop(\"label\")\n\n    testX_allFeats = pd.DataFrame(test_df)\n    testX_allFeats.pop(\"text\")\n    if \"BERT\" in testX_allFeats.columns:\n        testX_allFeats.pop(\"BERT\")\n    if \"Word2Vec\" in testX_allFeats.columns:\n        testX_allFeats.pop(\"Word2Vec\")\n#     testX_allFeats.pop(\"tokens\")\n    testX_allFeats.pop(\"id\")\n    testX_allFeats.pop(\"emotion_dict\")\n    testX_allFeats.pop(\"depression_dict\")\n    testX_allFeats.pop(\"post_id\")\n    testX_allFeats.pop(\"sentence_range\")\n    testX_allFeats.pop(\"social_timestamp\")\n    subreddit_encoded, sub_encoder = alpha_to_numerical(testX_allFeats[\"subreddit\"])\n    testX_allFeats[\"subreddit\"] = subreddit_encoded\n    emotion_encoded, em_encoder = alpha_to_numerical(testX_allFeats[\"emotion\"])\n    testX_allFeats[\"emotion\"] = emotion_encoded\n    depression_encoded, dep_encoder = alpha_to_numerical(testX_allFeats[\"depression\"])\n    testX_allFeats[\"depression\"] = depression_encoded\n    testY_allFeats = testX_allFeats[\"label\"]\n    testX_allFeats.pop(\"label\")\n\n    return trainX_allFeats, trainY_allFeats, testX_allFeats, testY_allFeats\n\n\ndef df_textEmbedsFeats_split(train_df,test_df, embedding_dim=BERT_EMB_OUT):\n    trainX_allFeats, trainY, testX_allFeats, testY = df_allFeats_split(train_df, test_df)\n    feats_to_keep = [ str(i) for i in range(embedding_dim)]\n\n    trainX_textEmbedsFeats = trainX_allFeats[feats_to_keep]\n    testX_textEmbedsFeats = testX_allFeats[feats_to_keep]\n\n    return trainX_textEmbedsFeats, trainY, testX_textEmbedsFeats, testY\n\n    return\n\ndef df_lexFeats_split(train_df,test_df,embedding_dim=BERT_EMB_OUT):\n    trainX_allFeats, trainY, testX_allFeats, testY = df_allFeats_split(train_df, test_df)\n    feats_to_keep = [ str(i) for i in range(embedding_dim)]\n    feats_to_keep.extend([ c for c in trainX_allFeats.columns if \"lex\" in c ])\n    feats_to_keep.append(\"sentiment\")\n\n\n    trainX_lexFeats = trainX_allFeats[feats_to_keep]\n    testX_lexFeats = testX_allFeats[feats_to_keep]\n\n    return trainX_lexFeats, trainY, testX_lexFeats, testY\n\ndef df_liwcFeats_split(train_df,test_df,embedding_dim=BERT_EMB_OUT):\n    trainX_allFeats, trainY, testX_allFeats, testY = df_allFeats_split(train_df, test_df)\n    feats_to_keep = [ str(i) for i in range(embedding_dim)]\n    feats_to_keep.extend([ c for c in trainX_allFeats.columns if \"liwc\" in c ])\n\n    trainX_liwcFeats = trainX_allFeats[feats_to_keep]\n    testX_liwcFeats = testX_allFeats[feats_to_keep]\n\n    return trainX_liwcFeats, trainY, testX_liwcFeats, testY\n\ndef df_dalFeats_split(train_df,test_df,embedding_dim=BERT_EMB_OUT):\n    trainX_allFeats, trainY, testX_allFeats, testY = df_allFeats_split(train_df, test_df)\n    feats_to_keep = [ str(i) for i in range(embedding_dim)]\n    feats_to_keep.extend([ c for c in trainX_allFeats.columns if c in [ \"emotion\", ] ])\n\n    trainX_dalFeats = trainX_allFeats[feats_to_keep]\n    testX_dalFeats = testX_allFeats[feats_to_keep]\n\n    return trainX_dalFeats, trainY, testX_dalFeats, testY\n\ndef df_onlyFeats_split(train_df,test_df,embedding_dim=BERT_EMB_OUT):\n    trainX_allFeats, trainY, testX_allFeats, testY = df_allFeats_split(train_df, test_df)\n    feats_to_keep = [ c for c in trainX_allFeats.columns if c not in [ str(i) for i in range(embedding_dim)] ]\n\n    trainX_onlyFeats = trainX_allFeats[feats_to_keep]\n    testX_onlyFeats = testX_allFeats[feats_to_keep]\n\n    return trainX_onlyFeats, trainY, testX_onlyFeats, testY\n    \ndef df_emDepFeats_split(train_df,test_df,embedding_dim=BERT_EMB_OUT):\n    trainX_allFeats, trainY, testX_allFeats, testY = df_allFeats_split(train_df, test_df)\n    feats_to_keep = [ str(i) for i in range(embedding_dim)]\n    feats_to_keep.extend([ c for c in trainX_allFeats.columns if any(substring in c for substring in [\"sad\", \"anger\", \"anx\", \"negemo\", \"posemo\", \"emotion\", \"depression\", \"sentiment\"]) ])\n\n    trainX_dalFeats = trainX_allFeats[feats_to_keep]\n    testX_dalFeats = testX_allFeats[feats_to_keep]\n\n    return trainX_dalFeats, trainY, testX_dalFeats, testY\n\ndef df_onlylexFeats_split(train_df,test_df,embedding_dim=BERT_EMB_OUT):\n    trainX_allFeats, trainY, testX_allFeats, testY = df_allFeats_split(train_df, test_df)\n    feats_to_keep = [ c for c in trainX_allFeats.columns if \"lex\" in c ]\n    feats_to_keep.append(\"sentiment\")\n\n\n    trainX_lexFeats = trainX_allFeats[feats_to_keep]\n    testX_lexFeats = testX_allFeats[feats_to_keep]\n\n    return trainX_lexFeats, trainY, testX_lexFeats, testY\n\ndef df_onlyliwcFeats_split(train_df,test_df,embedding_dim=BERT_EMB_OUT):\n    trainX_allFeats, trainY, testX_allFeats, testY = df_allFeats_split(train_df, test_df)\n    feats_to_keep = [ c for c in trainX_allFeats.columns if \"liwc\" in c ]\n\n    trainX_liwcFeats = trainX_allFeats[feats_to_keep]\n    testX_liwcFeats = testX_allFeats[feats_to_keep]\n\n    return trainX_liwcFeats, trainY, testX_liwcFeats, testY\n\ndef df_onlydalFeats_split(train_df,test_df,embedding_dim=BERT_EMB_OUT):\n    trainX_allFeats, trainY, testX_allFeats, testY = df_allFeats_split(train_df, test_df)\n    feats_to_keep = [ c for c in trainX_allFeats.columns if c in [ \"emotion\", ] ]\n\n    trainX_dalFeats = trainX_allFeats[feats_to_keep]\n    testX_dalFeats = testX_allFeats[feats_to_keep]\n\n    return trainX_dalFeats, trainY, testX_dalFeats, testY\n\ndef df_onlyemDepFeats_split(train_df,test_df,embedding_dim=BERT_EMB_OUT):\n    trainX_allFeats, trainY, testX_allFeats, testY = df_allFeats_split(train_df, test_df)\n    feats_to_keep = [ c for c in trainX_allFeats.columns if any(substring in c for substring in [\"sad\", \"anger\", \"anx\", \"negemo\", \"posemo\", \"emotion\", \"depression\", \"sentiment\"]) ]\n\n    trainX_dalFeats = trainX_allFeats[feats_to_keep]\n    testX_dalFeats = testX_allFeats[feats_to_keep]\n\n    return trainX_dalFeats, trainY, testX_dalFeats, testY\n\n\n\n#---------- MODEL EVALUATION -----------------------------------------------------------------------------------------\ndef precision_s(y_true, y_pred):\n    TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n\n    precision = TP / (Pred_Positives+K.epsilon())\n    return precision \n\ndef recall_s(y_true, y_pred):\n    TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n\n    recall = TP / (Positives+K.epsilon())    \n    return recall \n\ndef f1_s(y_true, y_pred):     \n    precision, recall = precision_s(y_true, y_pred), recall_s(y_true, y_pred)\n\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n\n# def precision_2(y_true,y_pred):\n#     y_true = np.array(y_true).reshape(-1)\n#     y_pred = np.array(y_pred).reshape(-1)\n#     return precision_score(y_true,y_pred)\n\n# def recall_2(y_true,y_pred):\n#     y_true = np.array(y_true).reshape(-1)\n#     y_pred = np.array(y_pred).reshape(-1)\n#     return recall_score(y_true,y_pred)\n\n# def f1_2(y_true,y_pred):\n#     y_true = np.array(y_true).reshape(-1)\n#     y_pred = np.array(y_pred).reshape(-1)\n#     return f1_score(y_true,y_pred)\n\n\ndef plot_learning_curves(history, string, model_path, feats, model_type):\n    model_name = model_path.split(\"/\")[-1]\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n\n    if \"_\" in string[-3:]:\n        string=string.split(\"_\")[0]\n\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string.capitalize())\n    plt.legend([\"train_\"+string, 'val_'+string])\n    plt.title(f\"{model_type}\\nMetric: {string.capitalize()}\\n({feats})\")\n    plt.savefig(os.path.join(model_path,f\"{model_name}_{string}_{feats}.png\"), dpi=300)\n    plt.show()\n\n\ndef plot_history(history,model_path,feats,model_type):\n    for metric in history.history.keys():\n        if \"val\" not in metric:\n            plot_learning_curves(history, metric, model_path,feats,model_type)    \n#         plot_learning_curves(history, 'loss', model_path)\n#         plot_learning_curves(history, 'precision_s', model_path)    \n#         plot_learning_curves(history, 'recall_s', model_path)\n#         plot_learning_curves(history, 'f1_s', model_path)\n\n\nfrom sklearn.metrics import confusion_matrix, classification_report\ndef class_report(model,trainX,trainY,testX,testY):\n    scores = model.evaluate(testX, testY, verbose=1)\n    predictions = model.predict(testX)\n    predictions=  np.round(predictions).reshape(max(predictions.shape)).astype(float)\n    true_y= testY.reshape(max(testY.shape)).astype(float)\n    labels = ['Not stressed', 'Stressed']\n    class_report_df_test = classification_report(testY.reshape(-1), predictions)\n    scores_df_test = pd.DataFrame(confusion_matrix(testY.reshape(-1), predictions), index=labels, columns=labels)\n    scores_str_test = f\"\\n\\nTest Set Classification Report\"+f\"\\nAccuracy: {scores[1]*100:.2f}%\\nLoss: {scores[0]:.3f}\\n\" +class_report_df_test+\"\\n\"+scores_df_test.to_string()  \n\n    scores = model.evaluate(trainX, trainY, verbose=1)\n    predictions = model.predict(trainX)\n    predictions=  np.round(predictions).reshape(max(predictions.shape)).astype(float)\n    true_y= trainY.reshape(max(trainY.shape)).astype(float)\n    labels = ['Not stressed', 'Stressed']\n    class_report_df_train = classification_report(trainY.reshape(-1), predictions)\n    scores_df_train = pd.DataFrame(confusion_matrix(trainY.reshape(-1), predictions), index=labels, columns=labels)\n    scores_str_train = f\"\\n\\nTrain Set Classification Report\"+f\"\\nAccuracy: {scores[1]*100:.2f}%\\nLoss: {scores[0]:.3f}\\n\" +class_report_df_train+\"\\n\"+scores_df_train.to_string()  \n#     print(scores_str_train)\n\n    class_score_str = scores_str_test+\"\\n\\n\"+scores_str_train+\"\\n\\n\"\n    \n    return class_score_str\n\n# scores_str = class_report(model_1,trainX,trainY,testX,testY)\n\n# Grid Search\ndef BiLSTM_to_optimizeRecall(lr, dropout_last_Dense, dense2_num, lstm1, lstm2, dropout_lstm):\n    loss_func = 'binary_crossentropy'\n    opt = Adam(learning_rate=lr)\n    model = model_biLSTM(dropout_last_Dense, dense2_num,  lstm1, lstm2, dropout_lstm)\n\n    model.compile(loss=loss_func, optimizer=opt, metrics=tf.keras.metrics.Recall())\n\n    return model\n\n\ndef CNN_to_optimizeRecall(filters1, k_s1, filters2, k_s2, dropout_last_Dense, denseLast_num):\n    loss_func = 'binary_crossentropy'\n    opt = Adam(learning_rate=lr)\n    model = model_CNN(filters1, k_s1, filters2, k_s2, dropout_last_Dense, denseLast_num)\n\n    model.compile(loss=loss_func, optimizer=opt, metrics=tf.keras.metrics.Recall())\n\n    return model\n\n\n\ndef ROC_curves_ALL_NNs(model_list,model_type_list,X,y,folder_path,feats,class_num):\n    plt.figure(figsize=(18,12))\n    for m,t in zip(model_list,model_type_list):\n        if t==\"CNN\":\n            X_set = X.reshape(X.shape[0], X.shape[1], -1) \n        else:\n            X_set = X.reshape(-1, 1, X.shape[1]) \n\n        y_true=y\n        y_pred = m.predict(X_set).ravel()\n        fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_true, y_pred)\n        auc_keras = auc(fpr_keras, tpr_keras)\n        plt.plot(fpr_keras, tpr_keras, label=f'{t} (area = {auc_keras:.2f})')\n\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'Receiver operating characteristic\\n({feats})')\n    plt.legend(loc=\"lower right\")\n    plt.savefig(os.path.join(folder_path,f'ROC_{feats}.png'), dpi=300)\n    plt.show()\n\n\ndef ROC_curves_NNsAlgos(model_list,model_type_list,X_nn,y_nn,X_algo,y_algo,folder_path,feats,class_num):\n    best_model = None\n    max_auc = 0\n    best_model_type = None\n    plt.figure(figsize=(18,12))\n    for m,t in zip(model_list,model_type_list):\n        if t in [\"CNN\", \"BiLSTM\", \"BiGRU\"]:\n            if t==\"CNN\":\n                X_set = X_nn.reshape(X_nn.shape[0], X_nn.shape[1], -1) \n            elif t in [\"BiLSTM\", \"BiGRU\"]:\n                X_set = X_nn.reshape(-1, 1, X_nn.shape[1])\n                y_true=y_nn\n            y_pred = m.predict(X_set).ravel()\n            fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_true, y_pred)\n            auc_keras = auc(fpr_keras, tpr_keras)\n            plt.plot(fpr_keras, tpr_keras, label=f'{t} (area = {auc_keras:.2f})')\n\n        else:    \n            auc_keras = roc_auc_score(y_algo, m.predict(X_algo))\n            fpr, tpr, thresholds = roc_curve(y_algo, m.predict_proba(X_algo)[:,1])\n            plt.plot(fpr, tpr, label=f'{t} (area = {auc_keras:.2f})')\n            \n        if auc_keras>max_auc:\n            max_auc=auc_keras\n            best_model=m\n            best_model_type=t\n        \n\n\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'Receiver operating characteristic\\n({feats})')\n    plt.legend(loc=\"lower right\")\n    plt.savefig(os.path.join(folder_path,f'ROC_{feats}.png'), dpi=300)\n    plt.show()\n    \n    return best_model,best_model_type\n\n\n# ROC Curves\ndef ROC_curve(model,model_type,X,y,folder_path):\n    logit_roc_auc = roc_auc_score(y, model.predict(X))\n    fpr, tpr, thresholds = roc_curve(y, model.predict_proba(X)[:,1])\n    plt.figure()\n    plt.plot(fpr, tpr, label=f'{model_type} (area = %0.2f)' % logit_roc_auc)\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.savefig(os.path.join(folder_path,f'{model_type}_ROC.png'),dpi=300)\n    plt.show()\n\ndef ROC_curves_ALL(model_list,model_type_list,X,y,folder_path,feats):\n    plt.figure(figsize=(18,12))\n    for m,t in zip(model_list,model_type_list):\n\n        logit_roc_auc = roc_auc_score(y, m.predict(X))\n        fpr, tpr, thresholds = roc_curve(y, m.predict_proba(X)[:,1])\n        plt.plot(fpr, tpr, label=f'{t} (area = %0.2f)' % logit_roc_auc)\n\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'Receiver operating characteristic\\n({feats})')\n    plt.legend(loc=\"lower right\")\n    plt.savefig(os.path.join(folder_path,f'ROC_{feats}.png'), dpi=300)\n    plt.show()\n\n\n# class_num =1\n# feats=\"allFeats\"\n# ROC_curves_ALL_NNs([model_1, model_2, model_3],[\"BiLSTM\", \"CNN\", \"BiGRU\"],testX_orig,testY_orig,file_store_dir,feats,class_num=class_num)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:22:49.628207Z","iopub.execute_input":"2022-07-13T19:22:49.629955Z","iopub.status.idle":"2022-07-13T19:22:50.074866Z","shell.execute_reply.started":"2022-07-13T19:22:49.629914Z","shell.execute_reply":"2022-07-13T19:22:50.073306Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"___\n___\n## Models \n___","metadata":{}},{"cell_type":"code","source":"\n#---------- CLASSIFICATION ALGORITHMS -----------------------------------------------------------------------------------------\n\ndef LR_classification(file_store_dir, trainX, trainY, testX, testY, feats):\n    # among several small values, 0.001 was the one optimizing the results - quicker convergence, higher scores\n    C=5e-5\n    # scaling=\"Standard\"\n    # LR = make_pipeline(StandardScaler(),LogisticRegression(C=C, solver=\"lbfgs\", max_iter=1000 ))\n    # scaling=\"Normal\"\n    # LR = make_pipeline(MinMaxScaler(),LogisticRegression(C=C, solver=\"lbfgs\", max_iter=1000 ))\n    scaling=\"noScaling\"\n    LR = LogisticRegression(C=C, solver=\"lbfgs\", max_iter=1000 )\n    LR.fit(trainX, trainY)\n    LR_scores_precision = evaluate_model_precision(LR, testX, testY)\n    LR_scores_recall = evaluate_model_recall(LR, testX, testY)\n    LR_scores_f1 = evaluate_model_f1(LR, testX, testY)\n\n    scores = f'\\n> Logistic Regression (C: {C})\\nmean F1: {mean(LR_scores_f1):.6f} | mean Precision: {mean(LR_scores_precision):.6f} | mean Recall: {mean(LR_scores_recall):.6f}\\nstd F1: {std(LR_scores_f1):.6f} | std Precision: {std(LR_scores_precision):.6f} | std Recall: {std(LR_scores_recall):.6f}'\n\n    y_pred = LR.predict(testX)\n    log_str = scores+\"\\n\\n\"+classification_report(testY, y_pred)+\"\\n\\n\"+str(LR.get_params())\n    print(log_str)\n\n    log_dir = os.path.join(file_store_dir,\"LogisticRegression\")\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n\n    log_path = os.path.join(log_dir,f\"LR_{scaling}_{feats}.txt\")\n    with open(log_path,\"w\",encoding=\"utf-8\") as log_writer:\n        log_writer.write(log_str)\n\n    return LR\n\ndef KNN_classification(file_store_dir, trainX, trainY, testX, testY, feats):\n    # among several values, 5 was the one optimizing the results\n    k_n=5\n    # scaling=\"Standard\"\n    # KNN = make_pipeline(StandardScaler(),KNeighborsClassifier(n_neighbors=k_n))\n    # scaling=\"Normal\"\n    # KNN = make_pipeline(MinMaxScaler(),KNeighborsClassifier(n_neighbors=k_n))\n    scaling=\"noScaling\"\n    KNN = KNeighborsClassifier(n_neighbors=k_n)\n    KNN.fit(trainX, trainY)\n    KNN_scores_precision = evaluate_model_precision(KNN, testX, testY)\n    KNN_scores_recall = evaluate_model_recall(KNN, testX, testY)\n    KNN_scores_f1 = evaluate_model_f1(KNN, testX, testY)\n\n    scores = f'\\n> k Nearest Neighbor (n_neighbors:{k_n}) \\nmean F1: {mean(KNN_scores_f1):.6f} | mean Precision: {mean(KNN_scores_precision):.6f} | mean Recall: {mean(KNN_scores_recall):.6f}\\nstd F1: {std(KNN_scores_f1):.6f} | std Precision: {std(KNN_scores_precision):.6f} | std Recall: {std(KNN_scores_recall):.6f}'\n\n    y_pred = KNN.predict(testX)\n    log_str = scores+\"\\n\\n\"+classification_report(testY, y_pred)+\"\\n\\n\"+str(KNN.get_params())\n    print(log_str)\n\n    log_dir = os.path.join(file_store_dir,\"KNearestNeighbors\")\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n\n    log_path = os.path.join(log_dir,f\"KNN_{scaling}_{feats}.txt\")\n    with open(log_path,\"w\",encoding=\"utf-8\") as log_writer:\n        log_writer.write(log_str)\n\n    return KNN\n\ndef SVM_classification(file_store_dir, trainX, trainY, testX, testY, feats):    \n    C=1.0\n    kernel=\"rbf\"\n    # scaling=\"Standard\"\n    # SVM = make_pipeline(StandardScaler(),SVC(C=C, kernel=kernel))\n    # scaling=\"Normal\"\n    # SVM = make_pipeline(MinMaxScaler(),SVC(C=C, kernel=kernel))\n    scaling=\"NoScaling\"\n    SVM = SVC(C=C, kernel=kernel,probability=True)\n    SVM.fit(trainX, trainY)\n    SVM_scores_precision = evaluate_model_precision(SVM, testX, testY)\n    SVM_scores_recall = evaluate_model_recall(SVM, testX, testY)\n    SVM_scores_f1 = evaluate_model_f1(SVM, testX, testY)\n\n    scores = f'\\n> Support Vector Machine (C: {C}) \\nmean F1: {mean(SVM_scores_f1):.6f} | mean Precision: {mean(SVM_scores_precision):.6f} | mean Recall: {mean(SVM_scores_recall):.6f}\\nstd F1: {std(SVM_scores_f1):.6f} | std Precision: {std(SVM_scores_precision):.6f} | std Recall: {std(SVM_scores_recall):.6f}'\n\n    y_pred = SVM.predict(testX)\n    log_str = scores+\"\\n\\n\"+classification_report(testY, y_pred)+\"\\n\\n\"+str(SVM.get_params())\n    print(log_str)\n\n    log_dir = os.path.join(file_store_dir,\"SupportVectorMachine\")\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n\n    log_path = os.path.join(log_dir,f\"SVM_{scaling}_{feats}.txt\")\n    with open(log_path,\"w\",encoding=\"utf-8\") as log_writer:\n        log_writer.write(log_str)\n\n    return SVM\n\ndef RF_classification(file_store_dir, trainX, trainY, testX, testY, feats):\n    n_estimators = 100\n    scaling=\"Standard\"\n    RF = make_pipeline(StandardScaler(),RandomForestClassifier(n_estimators=n_estimators))\n    # scaling=\"Normal\"\n    # RF = make_pipeline(MinMaxScaler(),RandomForestClassifier(n_estimators=n_estimators))\n    # scaling=\"NoScaling\"\n    # RF = RandomForestClassifier(n_estimators=n_estimators)\n    RF.fit(trainX, trainY)\n    RF_scores_precision = evaluate_model_precision(RF, testX, testY)\n    RF_scores_recall = evaluate_model_recall(RF, testX, testY)\n    RF_scores_f1 = evaluate_model_f1(RF, testX, testY)\n\n    scores = f'\\n> Random Forest \\nmean F1: {mean(RF_scores_f1):.6f} | mean Precision: {mean(RF_scores_precision):.6f} | mean Recall: {mean(RF_scores_recall):.6f}\\nstd F1: {std(RF_scores_f1):.6f} | std Precision: {std(RF_scores_precision):.6f} | std Recall: {std(RF_scores_recall):.6f}'\n\n    y_pred = RF.predict(testX)\n    log_str = scores+\"\\n\\n\"+classification_report(testY, y_pred)+\"\\n\\n\"+str(RF.get_params())\n    print(log_str)\n\n    log_dir = os.path.join(file_store_dir,\"RandomForest\")\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n\n    log_path = os.path.join(log_dir,f\"RF_{scaling}_{feats}.txt\")\n    with open(log_path,\"w\",encoding=\"utf-8\") as log_writer:\n        log_writer.write(log_str)\n        \n    return RF\n\n\n\n#---------- ARTIFICIAL NEURAL NETWORKS -----------------------------------------------------------------------------------------\n\n\ndef model_training(model,loss_func,opt,trainX,trainY,batch_size,epochs,testX,testY, csv_logger, metrics):\n    \n    model.compile(loss=loss_func, optimizer=opt, metrics=metrics)\n    history = model.fit(trainX, trainY, batch_size=batch_size, epochs=epochs, validation_data=(testX, testY), verbose=1, shuffle=True, callbacks=[csv_logger])\n    \n    return model, history\n    \n# model 1\ndef model_biLSTM(dropout2_drp=0.2, dense2_num=8, lstm1_num=32, lstm2_num=16, dropout_lstm=0.2):\n    kernel_reg=regularizers.l1_l2()\n#     kernel_reg=None\n    dense1_num=32\n    dense1_activation=\"relu\"\n\n    dropout1_drp=0.9\n    \n    dense2_activation=\"relu\"\n    \n    classes_num=1\n    final_activation=\"sigmoid\"\n    \n    model = Sequential()\n    model.add( Dense( dense1_num, activation=dense1_activation, kernel_regularizer=kernel_reg) )\n    model.add( Bidirectional(LSTM(lstm1_num, dropout = dropout_lstm, return_sequences=True,kernel_regularizer=kernel_reg  ) ) )\n#     model.add( Bidirectional(LSTM(lstm2_num)) )\n    model.add( Dense(dense2_num, activation=dense2_activation) )\n    model.add( Dropout(dropout2_drp) )\n    model.add( Dense(classes_num, activation=final_activation) )\n    \n    return model\n\n\n# model 2\ndef model_CNN(f1=16, k1_size=2, f2=8, k2_size=2, dropout2_drp=0.15, dense2_num=8):\n    dense2_activation=\"relu\"\n#     dropout2_drp=0.2\n    \n    classes_num=1\n    final_activation=\"sigmoid\"\n    \n    model = Sequential()\n    model.add(Conv1D(filters=f1, kernel_size=k1_size, padding=\"same\", activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Conv1D(filters=f2, kernel_size=k2_size, padding=\"same\", activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Flatten())\n    model.add(Dense(dense2_num, activation='relu'))\n    model.add( Dropout(dropout2_drp) )\n    model.add( Dense(classes_num, activation=final_activation) )\n\n    return model\n\n# model 3\ndef model_BiGRU():\n    dense2_num=8\n    dense2_activation=\"relu\"\n    dropout2_drp=0.2\n    \n    gru_units = 32\n    \n    classes_num=1\n    final_activation=\"sigmoid\"\n    \n    model = Sequential()\n    model.add( Bidirectional(CuDNNGRU(gru_units, return_sequences=True)))\n    model.add( Dropout(0.2))\n    model.add( Dense(gru_units*2, activation='relu'))\n    model.add( Dropout(0.1))\n    model.add( Dense(gru_units, activation='relu'))\n    model.add( Dropout(dropout2_drp) )\n    model.add( Dense(classes_num, activation=final_activation) )\n    \n    return model\n\n\n# model 1\ndef BiLSTM_classification(file_store_dir, trainX_orig, trainY_orig, testX_orig, testY_orig, epochs, feats):\n    model_name=\"modelBiLSTM\"\n    model_path=os.path.join(file_store_dir,f\"{model_name}\")\n    if not os.path.exists(model_path):\n        os.makedirs(model_path)\n\n    classes_num=1\n    # data set reshape\n    trainX = trainX_orig.reshape(-1, 1, trainX_orig.shape[1])\n    testX = testX_orig.reshape(-1, 1, testX_orig.shape[1])\n\n    # trainY = categorical_encoding(trainY_allFeats)\n    # trainY = trainY.reshape(-1, 1, classes_num)\n    trainY = trainY_orig.reshape(-1, 1, classes_num)\n\n    # testY= categorical_encoding(testY_allFeats)\n    # testY= testY.reshape(-1, 1, classes_num)\n    testY = testY_orig.reshape(-1, 1, classes_num)\n\n    loss_fun = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    lr = 5e-5\n    opt = Adam(learning_rate=lr)\n    # opt = RMSprop(learning_rate=lr)\n    batch_size = 24\n#     epochs = 20\n\n    csv_logger = CSVLogger(os.path.join(model_path,f'log_{model_name}_{feats}.csv'), separator=',' )\n    metrics= [ \"accuracy\", tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5), tf.keras.metrics.Precision(), tf.keras.metrics.Recall() ]\n    # metrics = [\"accuracy\",f1_s,precision_s,recall_s]\n    model_1 = model_biLSTM()\n    print(f\"\\n\\nBiLSTM\\n\")\n    model_1, history_1 = model_training(model_1,loss_fun,opt,trainX,trainY,batch_size,epochs,testX,testY, csv_logger, metrics)\n\n    loss, accuracy, f1_score, precision, recall = model_1.evaluate(trainX, trainY, verbose=0)\n    eval_str_training = f\"\\nBiLSTM\\n\\nTraining Set\\nLoss: {loss: .6f}\\nAccuracy: {accuracy:.6f}\\nPrecision: {precision:.6f}\\nRecall: {recall:.6f}\\nF1: {f1_score:.6f}\\n\\n\"\n    loss, accuracy, f1_score, precision, recall = model_1.evaluate(testX, testY, verbose=0)\n    eval_str_test = f\"\\n\\nTest Set\\nLoss: {loss: .6f}\\nAccuracy: {accuracy:.6f}\\nPrecision: {precision:.6f}\\nRecall: {recall:.6f}\\nF1: {f1_score:.6f}\\n\\n\"\n    # print(\"\\n\\n\"+eval_str_training, eval_str_test)\n\n#     plot_history(history_1, model_path,feats, \"BiLSTM\")\n\n    with open(os.path.join(model_path,f\"{model_name}_evaluationScore_{feats}.txt\"),\"w\",encoding=\"utf-8\") as evaluation_file:\n        evaluation_file.write(class_report(model_1,trainX,trainY,testX,testY))\n        evaluation_file.write(\"\\n\\n\"+eval_str_training+eval_str_test)\n\n#     from IPython.display import FileLink, FileLinks\n#     FileLinks(\".\")\n\n    print(f\"\\n{class_report(model_1,trainX,trainY,testX,testY)}\" )\n    \n    return model_1, history_1\n\n## model 2\ndef CNN_classification(file_store_dir, trainX_orig, trainY_orig, testX_orig, testY_orig, epochs, feats):\n    model_name=\"modelCNN\"\n    model_path=os.path.join(file_store_dir,f\"{model_name}\")\n    if not os.path.exists(model_path):\n        os.makedirs(model_path)\n\n    classes_num=1\n    # data set reshape\n    trainX = trainX_orig.reshape(trainX_orig.shape[0], trainX_orig.shape[1], -1)\n    testX = testX_orig.reshape(testX_orig.shape[0], testX_orig.shape[1], -1)\n\n    # le = LabelEncoder()\n    # trainY = categorical_encoding(trainY_allFeats)\n    # trainY = trainY.reshape(-1, 1, classes_num)\n    trainY = trainY_orig.reshape(-1, classes_num)\n    # trainY = le.fit_transform()\n\n    # testY= categorical_encoding(testY_allFeats)\n    # testY= testY.reshape(-1, 1, classes_num)\n    testY = testY_orig.reshape(-1, classes_num)\n\n    loss_fun = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    lr = 5e-5\n    opt = Adam(learning_rate=lr)\n    # opt = RMSprop(learning_rate=lr)\n    batch_size = 24\n#     epochs = 20\n\n    csv_logger = CSVLogger(os.path.join(model_path,f'log_{model_name}_{feats}.csv'), separator=',')\n    metrics= [ \"accuracy\", tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5), tf.keras.metrics.Precision(), tf.keras.metrics.Recall() ]\n\n    model_2= model_CNN()\n    print(f\"\\n\\nCNN\\n\")\n    model_2,history_2 = model_training(model_2,loss_fun,opt,trainX,trainY,batch_size,epochs,testX,testY, csv_logger, metrics)\n\n    loss, accuracy, f1_score, precision, recall = model_2.evaluate(trainX, trainY, verbose=0)\n    eval_str_training = f\"\\nCNN\\n\\nTraining Set\\nLoss: {loss: .6f}\\nAccuracy: {accuracy:.6f}\\nPrecision: {precision:.6f}\\nRecall: {recall:.6f}\\nF1: {f1_score:.6f}\\n\\n\"\n    loss, accuracy, f1_score, precision, recall = model_2.evaluate(testX, testY, verbose=0)\n    eval_str_test = f\"\\n\\nTest Set\\nLoss: {loss: .6f}\\nAccuracy: {accuracy:.6f}\\nPrecision: {precision:.6f}\\nRecall: {recall:.6f}\\nF1: {f1_score:.6f}\\n\\n\"\n    # print(\"\\n\\n\"+eval_str_training, eval_str_test)\n\n#     plot_history(history_2, model_path, feats, \"CNN\")\n\n    with open(os.path.join(model_path,f\"{model_name}_evaluationScore_{feats}.txt\"),\"w\",encoding=\"utf-8\") as evaluation_file:\n        evaluation_file.write(class_report(model_2,trainX,trainY,testX,testY))\n        evaluation_file.write(\"\\n\\n\"+eval_str_training+eval_str_test)\n\n#     from IPython.display import FileLink, FileLinks\n#     FileLinks(\".\")   \n    print(f\"\\n{class_report(model_2,trainX,trainY,testX,testY)}\" )\n    \n    return model_2, history_2\n\n## model 3\ndef BiGRU_classification(file_store_dir, trainX_orig, trainY_orig, testX_orig, testY_orig, epochs, feats):\n    model_name=\"modelBiGRU\"\n    model_path=os.path.join(file_store_dir,f\"{model_name}\")\n    if not os.path.exists(model_path):\n        os.makedirs(model_path)\n\n    classes_num=1\n    # # data set reshape\n    trainX = trainX_orig.reshape(-1, 1, trainX_orig.shape[1])\n    testX = testX_orig.reshape(-1, 1, testX_orig.shape[1])\n\n    # trainY = categorical_encoding(trainY_allFeats)\n    # trainY = trainY.reshape(-1, 1, classes_num)\n    trainY = trainY_orig.reshape(-1, 1, classes_num)\n\n    # testY= categorical_encoding(testY_allFeats)\n    # testY= testY.reshape(-1, 1, classes_num)\n    testY = testY_orig.reshape(-1, 1, classes_num)\n\n    loss_fun = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    lr = 5e-5\n    opt = Adam(learning_rate=lr)\n    # opt = RMSprop(learning_rate=lr)\n    batch_size = 24\n#     epochs = 20\n\n    csv_logger = CSVLogger(os.path.join(model_path,f'log_{model_name}_{feats}.csv'), separator=',')\n    metrics= [ \"accuracy\", tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5), tf.keras.metrics.Precision(), tf.keras.metrics.Recall() ]\n\n    model_3= model_BiGRU()\n    print(f\"\\n\\nBiGRU\\n\")\n    model_3,history_3 = model_training(model_3,loss_fun,opt,trainX,trainY,batch_size,epochs,testX,testY, csv_logger, metrics)\n\n    loss, accuracy, f1_score, precision, recall = model_3.evaluate(trainX, trainY, verbose=0)\n    eval_str_training = f\"\\nBiGRU\\n\\nTraining Set\\nLoss: {loss: .6f}\\nAccuracy: {accuracy:.6f}\\nPrecision: {precision:.6f}\\nRecall: {recall:.6f}\\nF1: {f1_score:.6f}\\n\\n\"\n    loss, accuracy, f1_score, precision, recall = model_3.evaluate(testX, testY, verbose=0)\n    eval_str_test = f\"\\n\\nTest Set\\nLoss: {loss: .6f}\\nAccuracy: {accuracy:.6f}\\nPrecision: {precision:.6f}\\nRecall: {recall:.6f}\\nF1: {f1_score:.6f}\\n\\n\"\n    # print(\"\\n\\n\"+eval_str_training, eval_str_test)\n\n#     plot_history(history_3, model_path, feats, \"BiGRU\")\n\n    with open(os.path.join(model_path,f\"{model_name}_evaluationScore_{feats}.txt\"),\"w\",encoding=\"utf-8\") as evaluation_file:\n        evaluation_file.write(class_report(model_3,trainX,trainY,testX,testY))\n        evaluation_file.write(\"\\n\\n\"+eval_str_training+eval_str_test)\n    \n    print(f\"\\n{class_report(model_3,trainX,trainY,testX,testY)}\" )\n#     from IPython.display import FileLink, FileLinks\n#     FileLinks(\".\")   \n\n    return model_3, history_3    \n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:22:50.076815Z","iopub.execute_input":"2022-07-13T19:22:50.077184Z","iopub.status.idle":"2022-07-13T19:22:50.152526Z","shell.execute_reply.started":"2022-07-13T19:22:50.077150Z","shell.execute_reply":"2022-07-13T19:22:50.151239Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"___\n### Dataset Modifications/Additions\n___","metadata":{}},{"cell_type":"code","source":"def emb_feats_df(df,embs,dim):\n    \n    embs = [ eval(enc) if type(enc)!=list else enc for enc in embs ]\n\n    text_embed_names = [ str(i) for i in range(dim) ]\n    embs_df = pd.DataFrame(embs, columns=text_embed_names)\n    embFeats_df = embs_df.join(df)\n    \n    return embFeats_df\n\ndef token_WVs(text_list, w2v_model):\n    all_tokens = [ t for t_list in text_list for t in t_list ]\n    count_unknown=0\n    \n    unk_vector = np.zeros(w2v_model[\"the\"].shape)\n    nump_zero_arrs=[  unk_vector for t in all_tokens ]\n    token_dict={k:v for k,v in zip(all_tokens,nump_zero_arrs)}\n    for tok in all_tokens:\n        if tok in w2v_model:\n            token_dict[tok]=w2v_model[tok]\n        else:\n            count_unknown+=1\n    \n    token_dict[\"<UNK>\"] = np.zeros(w2v_model[\"the\"].shape)\n    \n    return token_dict, count_unknown\n\n\ndef text_WVs(text_list, token_vectors):\n#     for text in text_list:\n#         sent_vect_mean = \n    \n    sentence_vects =[ np.array( [ token_vectors[token] if token in token_vectors else token_vectors[\"<UNK>\"]  for token in s_tokens ] ).mean(axis=0) if len(s_tokens)>0 else token_vectors[\"<UNK>\"] for s_tokens in text_list    ]      \n    return sentence_vects\n\n\nWord2Vec_path = \"/kaggle/working/Word2Vec/\"\nif not os.path.exists(Word2Vec_path):\n    os.makedirs(Word2Vec_path)\n\nWord2Vec_news = os.path.join(Word2Vec_path,\"GoogleNews-vectors-negative300.bin.gz\")\n\nif not os.path.exists(Word2Vec_news[:-3]):\n    %cd {Word2Vec_path}\n    !gdown 0B7XkCwpI5KDYNlNUTTlSS21pQmM\n    !gunzip GoogleNews-vectors-negative300.bin.gz\n\n%cd /kaggle/working\nWord2Vec_news_emb_file = os.path.join(Word2Vec_path,\"GoogleNews-vectors-negative300.bin\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:22:50.155690Z","iopub.execute_input":"2022-07-13T19:22:50.156401Z","iopub.status.idle":"2022-07-13T19:23:44.346464Z","shell.execute_reply.started":"2022-07-13T19:22:50.156349Z","shell.execute_reply":"2022-07-13T19:23:44.344781Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def create_sentence_embeddings():    \n    # gpu_clean()\n    # load original dataset\n    dataset_train = \"/kaggle/input/stress-analysis-in-social-media/dreaddit-train.csv\"\n    dataset_test = \"/kaggle/input/stress-analysis-in-social-media/dreaddit-test.csv\"\n    train_df = pd.read_csv(dataset_train)\n    test_df = pd.read_csv(dataset_test)\n\n    # create embeddings\n    train_sent_embs,test_sent_embs = BERT_sentence_emb(train_df[\"text\"],test_df[\"text\"], bert_tok_name='bert-base-uncased')\n    train_embs, test_embs = get_sentence_embs(train_sent_embs, test_sent_embs)\n    # BERT_embFeats_train = join_embs_feats(train_embs,train_df_SED_text)\n    # BERT_embFeats_test = join_embs_feats(test_embs,test_df_SED_text)\n\n\n\n    # load stress-emotion-depression dataset\n    dataset_train_SED_text = \"/kaggle/input/sed-text-dataset/stressTrainEmDepr.csv\"\n    dataset_test_SED_text = \"/kaggle/input/sed-text-dataset/stressTestEmDepr.csv\"\n    train_df_SED_text = pd.read_csv(dataset_train_SED_text)\n    test_df_SED_text = pd.read_csv(dataset_test_SED_text)\n\n    google_news_vectors = KeyedVectors.load_word2vec_format(Word2Vec_news_emb_file, binary=True)\n\n    add_tokens_col(train_df_SED_text)\n    text_list = list(train_df_SED_text[\"tokens\"].values)\n    token_vectors_dict_train,unk_words = token_WVs(text_list, google_news_vectors)\n    print(f\"\\nTraining Set unknown Words: {unk_words} ({unk_words/(len(token_vectors_dict_train)-1)*100:.2f}%)\")\n    sentence_vectors_train = text_WVs(text_list, token_vectors_dict_train)\n\n\n    add_tokens_col(test_df_SED_text)\n    text_list = list(test_df_SED_text[\"tokens\"].values)\n    token_vectors_dict_test,unk_words = token_WVs(text_list, google_news_vectors)\n    print(f\"\\nTest Set unknown Words: {unk_words} ({unk_words/(len(token_vectors_dict_test)-1)*100:.2f}%)\")\n    sentence_vectors_test = text_WVs(text_list, token_vectors_dict_test)\n\n\n\n    train_sent_embs, test_sent_embs= [ vect.tolist() for vect in train_sent_embs], [ vect.tolist() for vect in test_sent_embs]\n    bert_train = pd.Series(train_sent_embs)\n    bert_test =  pd.Series(test_sent_embs)\n    sentence_vectors_train, sentence_vectors_test= [ vect.tolist() for vect in sentence_vectors_train], [ vect.tolist() for vect in sentence_vectors_test]\n    Word2Vec_train =  pd.Series(sentence_vectors_train)\n    Word2Vec_test=  pd.Series(sentence_vectors_test)\n\n    train_df_SED_text[\"BERT\"] = bert_train.values\n    test_df_SED_text[\"BERT\"] =  bert_test.values\n    train_df_SED_text[\"Word2Vec\"] =  Word2Vec_train.values\n    test_df_SED_text[\"Word2Vec\"] =  Word2Vec_test.values\n\n\n    # save dataframes\n    train_df_SED_text.to_csv(os.path.join(file_store_dir,\"stressTrainEmDep_BERTnWord2Vec_text.csv\"),  index = False, header=True)\n    test_df_SED_text.to_csv(os.path.join(file_store_dir,\"stressTestEmDep_BERTnWord2Vec_text.csv\"),  index = False, header=True)\n\n    FileLinks(\".\")","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:23:44.348789Z","iopub.execute_input":"2022-07-13T19:23:44.350227Z","iopub.status.idle":"2022-07-13T19:23:44.370358Z","shell.execute_reply.started":"2022-07-13T19:23:44.350181Z","shell.execute_reply":"2022-07-13T19:23:44.368912Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"___\n___\n\n# Experiments Wrapped Up !\n___\n## **Stress Detection**\n\n#### Application of text classification tasks based on paper **[\"Dreaddit: A Reddit Dataset for Stress Analysis in Social Media\"](https://arxiv.org/pdf/1911.00133v1.pdf)**\n\n___\n","metadata":{}},{"cell_type":"code","source":"def run_all(file_store_dir, trainX, trainY, testX, testY, feats, text_emb_type=\"BERT\", epochs=12):\n    print(f\"\\n\\n\\n--> {feats} <--\\n\")\n    # create log file directories\n    file_store_dir_classAlgos = os.path.join(file_store_dir,\"Algorithms\")\n    file_store_dir_classNNs = os.path.join(file_store_dir,\"NNs\")\n    for d in [file_store_dir_classAlgos, file_store_dir_classNNs]:\n        if not os.path.exists(d):\n            os.makedirs(d)\n    \n    model_names=[\"modelBiLSTM\",\"modelCNN\",\"modelBiGRU\"]\n    model_paths = []\n    for n in model_names:\n        model_path=os.path.join(file_store_dir,f\"{n}\")\n        model_paths.append(model_path)\n        if not os.path.exists(model_path):\n            os.makedirs(model_path)\n\n\n    # Classifiers\n    print(\"\\n\\nClassification Algorithms\")\n    # Algorithms\n    trainX_algo, trainY_algo, testX_algo, testY_algo = trainX.copy(), trainY.copy(), testX.copy(), testY.copy()\n    LR = LR_classification(file_store_dir_classAlgos, trainX_algo, trainY_algo, testX_algo, testY_algo, feats)\n    KNN = KNN_classification(file_store_dir_classAlgos, trainX_algo, trainY_algo, testX_algo, testY_algo, feats)\n    SVM = SVM_classification(file_store_dir_classAlgos, trainX_algo, trainY_algo, testX_algo, testY_algo, feats)\n    RF = RF_classification(file_store_dir_classAlgos, trainX_algo, trainY_algo, testX_algo, testY_algo, feats)\n\n    print(\"\\n\\nArtificial NNs\")\n    # Artificial NNs\n    trainX_orig, trainY_orig, testX_orig, testY_orig = trainX.values, trainY.values.astype(float), testX.values, testY.values.astype(float)\n    modelBiLSTM, historyBiLSTM = BiLSTM_classification(file_store_dir_classNNs, trainX_orig, trainY_orig, testX_orig, testY_orig, epochs, feats)\n    plot_history(historyBiLSTM, model_paths[0], feats, \"BiLSTM\")\n    \n    trainX_orig, trainY_orig, testX_orig, testY_orig = trainX.values, trainY.values.astype(float), testX.values, testY.values.astype(float)\n    modelCNN, historyCNN = CNN_classification(file_store_dir_classNNs, trainX_orig, trainY_orig, testX_orig, testY_orig, epochs, feats)\n    plot_history(historyCNN, model_paths[1], feats, \"CNN\")\n    \n    trainX_orig, trainY_orig, testX_orig, testY_orig = trainX.values, trainY.values.astype(float), testX.values, testY.values.astype(float)\n    modelBiGRU, historyBiGRU = BiGRU_classification(file_store_dir_classNNs, trainX_orig, trainY_orig, testX_orig, testY_orig, epochs, feats)\n    plot_history(historyBiGRU, model_paths[2], feats, \"BiGRU\")\n\n    # Evaluation\n    class_num=1\n    ROC_curves_ALL([LR,KNN,SVM,RF],[\"LogReg\",\"kNearestN\",\"SVM\",\"RandomForest\"],testX_algo,testY_algo,file_store_dir_classAlgos,feats)\n    ROC_curves_ALL_NNs([modelBiLSTM,modelCNN,modelBiGRU],[\"BiLSTM\",\"CNN\",\"BiGRU\"],testX_orig,testY_orig,file_store_dir_classNNs,feats,class_num=class_num)\n\n    model_list = [ LR, KNN, SVM, RF, modelBiLSTM, modelCNN, modelBiGRU ]\n    model_type_list = [ \"LogisticRegression\", \"KNearestNeihbor\", \"SupportVectorMachine\", \"RandomForest\", \"BiLSTM\", \"CNN\", \"BiGRU\" ]\n    best_model, best_model_type = ROC_curves_NNsAlgos(model_list,model_type_list,testX_orig,testY_orig,testX_algo,testY_algo,file_store_dir,feats,class_num)\n\n\n    # Save all results to a .zip file\n    zipname=os.path.join(file_store_dir,f\"{text_emb_type}_{feats}_Results.zip\")\n    !zip -r {zipname} {file_store_dir}\n    \n    return best_model, f\"{best_model_type}_{feats}\"\n\n\ndef run_all_feats(file_store_dir,train_df, test_df, text_emb_type=\"BERT\"):\n    emb_dim=BERT_EMB_OUT\n    if text_emb_type==\"Word2Vec\":\n        emb_dim=Word2Vec_EMB_OUT\n        \n    \n    best_models, best_model_types = [], []\n    # Feature selection\n    # __________________________________________________\n    \n    # Only Text embeddings to check the contribution of the features in the next step\n    feats=\"onlyTextEmbeds\"\n    trainX, trainY, testX, testY = df_textEmbedsFeats_split(train_df,test_df, emb_dim)\n    feats_dir = os.path.join(file_store_dir,f\"{feats}\")\n    bm,bmt = run_all(feats_dir, trainX, trainY, testX, testY, feats, text_emb_type)\n    best_models.append(bm)\n    best_model_types.append(bmt)    \n    \n    # All Features selected\n    feats=\"allFeats\"\n    trainX, trainY, testX, testY = df_allFeats_split(train_df, test_df)\n    feats_dir = os.path.join(file_store_dir,f\"{feats}\")\n    bm,bmt = run_all(feats_dir, trainX, trainY, testX, testY, feats, text_emb_type, epochs=20)\n    best_models.append(bm)\n    best_model_types.append(bmt) \n\n    # Linguistic Inquiry and Word Count features selected\n    feats=\"LIWC\"\n    trainX, trainY, testX, testY = df_liwcFeats_split(train_df,test_df, emb_dim)\n    feats_dir = os.path.join(file_store_dir,f\"{feats}\")\n    bm,bmt = run_all(feats_dir, trainX, trainY, testX, testY, feats, text_emb_type)\n    best_models.append(bm)\n    best_model_types.append(bmt) \n\n    # Dictionary of Affect in Language features selected\n    feats=\"DAL\"\n    trainX, trainY, testX, testY = df_dalFeats_split(train_df,test_df, emb_dim)\n    feats_dir = os.path.join(file_store_dir,f\"{feats}\")\n    bm,bmt = run_all(feats_dir, trainX, trainY, testX, testY, feats, text_emb_type)\n    best_models.append(bm)\n    best_model_types.append(bmt) \n\n    # Lexical features selected (LIWC + DAL + sentiment)\n    feats=\"Lex\"\n    trainX, trainY, testX, testY = df_lexFeats_split(train_df,test_df, emb_dim)\n    feats_dir = os.path.join(file_store_dir,f\"{feats}\")\n    bm,bmt = run_all(feats_dir, trainX, trainY, testX, testY, feats, text_emb_type)\n    best_models.append(bm)\n    best_model_types.append(bmt) \n\n\n    # Emotion - Depression features selected from LIWC + DAL + sentiment + emotion/depression dictionary\n    feats=\"EmDep\"\n    trainX, trainY, testX, testY = df_emDepFeats_split(train_df,test_df, emb_dim)\n    feats_dir = os.path.join(file_store_dir,f\"{feats}\")\n    bm,bmt = run_all(feats_dir, trainX, trainY, testX, testY, feats, text_emb_type)\n    best_models.append(bm)\n    best_model_types.append(bmt) \n\n    \n    \n# #     ---------- Testing the features' contribution ! - experimentation -------------------------------\n#     Only the Features are selected\n    feats=\"onlyFeats\"\n    trainX, trainY, testX, testY = df_onlyFeats_split(train_df, test_df)\n    feats_dir = os.path.join(file_store_dir,f\"{feats}\")\n    bm,bmt = run_all(feats_dir, trainX, trainY, testX, testY, feats, text_emb_type, epochs=20)\n    best_models.append(bm)\n    best_model_types.append(bmt)\n\n    \n#     Linguistic Inquiry and Word Count features selected\n    feats=\"onlyLIWC\"\n    trainX, trainY, testX, testY = df_onlyliwcFeats_split(train_df,test_df, emb_dim)\n    feats_dir = os.path.join(file_store_dir,f\"{feats}\")\n    bm,bmt = run_all(feats_dir, trainX, trainY, testX, testY, feats, text_emb_type)\n    best_models.append(bm)\n    best_model_types.append(bmt)\n    \n#     Dictionary of Affect in Language features selected\n#     feats=\"onlyDAL\"\n#     trainX, trainY, testX, testY = df_onlydalFeats_split(train_df,test_df, emb_dim)\n#     feats_dir = os.path.join(file_store_dir,f\"{feats}\")\n#     bm,bmt = run_all(feats_dir, trainX, trainY, testX, testY, feats, text_emb_type)\n#     best_models.append(bm)\n#     best_model_types.append(bmt)\n\n    # Lexical features selected (LIWC + DAL + sentiment)\n    feats=\"onlyLex\"\n    trainX, trainY, testX, testY = df_onlylexFeats_split(train_df,test_df, emb_dim)\n    feats_dir = os.path.join(file_store_dir,f\"{feats}\")\n    bm,bmt = run_all(feats_dir, trainX, trainY, testX, testY, feats, text_emb_type)\n    best_models.append(bm)\n    best_model_types.append(bmt)\n\n    # Emotion - Depression features selected from LIWC + DAL + sentiment + emotion/depression dictionary\n    feats=\"onlyEmDep\"\n    trainX, trainY, testX, testY = df_onlyemDepFeats_split(train_df,test_df, emb_dim)\n    feats_dir = os.path.join(file_store_dir,f\"{feats}\")\n    bm,bmt = run_all(feats_dir, trainX, trainY, testX, testY, feats, text_emb_type)\n    best_models.append(bm)\n    best_model_types.append(bmt)\n    \n    return best_models, best_model_types\n","metadata":{"execution":{"iopub.status.busy":"2022-07-05T17:45:21.933391Z","iopub.execute_input":"2022-07-05T17:45:21.933894Z","iopub.status.idle":"2022-07-05T17:45:22.020523Z","shell.execute_reply.started":"2022-07-05T17:45:21.933847Z","shell.execute_reply":"2022-07-05T17:45:22.019055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run the imports and define functions\nfile_store_dir = \"/kaggle/working/results\"\nif not os.path.exists(file_store_dir):\n    os.makedirs(file_store_dir)\n\nfile_store_dir_BERT = \"/kaggle/working/results/BERT\"\nif not os.path.exists(file_store_dir_BERT):\n    os.makedirs(file_store_dir_BERT)\n    \nfile_store_dir_Word2Vec = \"/kaggle/working/results/Word2Vec\"\nif not os.path.exists(file_store_dir_Word2Vec):\n    os.makedirs(file_store_dir_Word2Vec)\n    \n#---- Data ---- \n# Download the saved datasets\ndataset_train_embs = \"/kaggle/working/stressTrainEmDep_BERTnWord2Vec_text.csv\"\ndataset_test_embs = \"/kaggle/working/stressTestEmDep_BERTnWord2Vec_text.csv\"\n\nif not os.path.exists(dataset_train_embs):\n    !gdown 1IcrTBMXnXkcrBo543NDjGH7UT3QLYNa-\n    !gdown 1mtp-OP249SJsj-LYTEFbHpArcRwpOqte\n\n\n# BERT\ntrain_df_embs = pd.read_csv(dataset_train_embs)\ntest_df_embs = pd.read_csv(dataset_test_embs)\nBERT_feats_df_train = emb_feats_df(train_df_embs,train_df_embs[\"BERT\"],BERT_EMB_OUT)\nBERT_feats_df_test = emb_feats_df(test_df_embs, test_df_embs[\"BERT\"],BERT_EMB_OUT)\n\n# Word2Vec\ntrain_df_embs = pd.read_csv(dataset_train_embs)\ntest_df_embs = pd.read_csv(dataset_test_embs)\nWord2Vec_feats_df_train = emb_feats_df(train_df_embs,train_df_embs[\"Word2Vec\"],Word2Vec_EMB_OUT)\nWord2Vec_feats_df_test = emb_feats_df(train_df_embs, test_df_embs[\"Word2Vec\"],Word2Vec_EMB_OUT)\n\n# print(\"\\n\\n\\nBERT Sentence Embeddings\\n\")\n# best_models_BERT,best_model_types_BERT = run_all_feats(file_store_dir_BERT, BERT_feats_df_train, BERT_feats_df_test, \"BERT\")\n# ROC_curves_NNsAlgos(best_models_BERT,best_model_types_BERT,testX_orig,testY_orig,testX_algo,testY_algo,file_store_dir_BERT,\"BERT\",class_num)\n\nprint(\"\\n\\n\\nWord2Vec Google News Sentence Embeddings\\n\")\nbest_models_Word2Vec,best_model_types_Word2Vec  = run_all_feats(file_store_dir_Word2Vec, Word2Vec_feats_df_train, Word2Vec_feats_df_test, \"Word2Vec\")\n# ROC_curves_NNsAlgos(best_models_Word2Vec,best_model_types_Word2Vec,testX_orig,testY_orig,testX_algo,testY_algo,file_store_dir_Word2Vec,\"Word2Vec\",class_num)\n\n\n# Display all file links to download\nFileLinks(\".\")   \n","metadata":{"execution":{"iopub.status.busy":"2022-07-05T17:45:23.620329Z","iopub.execute_input":"2022-07-05T17:45:23.620906Z","iopub.status.idle":"2022-07-05T18:14:01.945345Z","shell.execute_reply.started":"2022-07-05T17:45:23.620869Z","shell.execute_reply":"2022-07-05T18:14:01.944138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save all results to a .zip file\nzipname=os.path.join(\"/kaggle/working\",f\"Results_final.zip\")\n!zip -r {zipname} /kaggle/working\n    \n# Display all file links to download\nFileLinks(\".\")   ","metadata":{"execution":{"iopub.status.busy":"2022-07-05T18:14:52.912304Z","iopub.execute_input":"2022-07-05T18:14:52.912725Z","iopub.status.idle":"2022-07-05T18:15:02.972002Z","shell.execute_reply.started":"2022-07-05T18:14:52.912689Z","shell.execute_reply":"2022-07-05T18:15:02.970759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}